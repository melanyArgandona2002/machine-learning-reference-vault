{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SECOND WEEK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "##  1. Example of activation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Define common activation functions\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def relu(z):\n",
        "    return np.maximum(0, z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def linear(z):\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "def tanh(z):\n",
        "    return np.tanh(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Generate data for visualization\n",
        "z = np.linspace(-10, 10, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualize activation functions\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(z, sigmoid(z), label='Sigmoid')\n",
        "plt.plot(z, relu(z), label='ReLU')\n",
        "plt.plot(z, linear(z), label='Linear')\n",
        "plt.plot(z, tanh(z), label='TanH')\n",
        "plt.title('Activation Functions')\n",
        "plt.xlabel('z')\n",
        "plt.ylabel('g(z)')\n",
        "plt.axhline(0, color='black', linewidth=0.5, linestyle='--')\n",
        "plt.axvline(0, color='black', linewidth=0.5, linestyle='--')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Example: Why linear functions limit learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Neural network with linear activation in all layers\n",
        "def forward_linear(x, w1, b1, w2, b2):\n",
        "    a1 = linear(w1 * x + b1)\n",
        "    a2 = linear(w2 * a1 + b2)\n",
        "    return a2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Example parameters\n",
        "w1, b1 = 2, 1\n",
        "w2, b2 = 0.5, -1\n",
        "x_values = np.linspace(-10, 10, 100)\n",
        "y_values = forward_linear(x_values, w1, b1, w2, b2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualize output\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(x_values, y_values, label='Output a2 (Linear)')\n",
        "plt.title('Limitations of Linear Activation')\n",
        "plt.xlabel('Input x')\n",
        "plt.ylabel('Output a2')\n",
        "plt.axhline(0, color='black', linewidth=0.5, linestyle='--')\n",
        "plt.axvline(0, color='black', linewidth=0.5, linestyle='--')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# 3. Using ReLU for better modeling capability\n",
        "def forward_relu(x, w1, b1, w2, b2):\n",
        "    a1 = relu(w1 * x + b1)\n",
        "    a2 = relu(w2 * a1 + b2)\n",
        "    return a2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Output with ReLU\n",
        "y_relu_values = forward_relu(x_values, w1, b1, w2, b2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Visualize output with ReLU\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(x_values, y_relu_values, label='Output a2 (ReLU)')\n",
        "plt.title('Modeling Capability with ReLU')\n",
        "plt.xlabel('Input x')\n",
        "plt.ylabel('Output a2')\n",
        "plt.axhline(0, color='black', linewidth=0.5, linestyle='--')\n",
        "plt.axvline(0, color='black', linewidth=0.5, linestyle='--')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MULTICLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate a synthetic dataset for multi-class classification\n",
        "Here, we use a simple dataset with 3 classes to demonstrate the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Generate 1000 samples with 3 features\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(1000, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Generate random labels for 3 classes\n",
        "y = np.random.choice([0, 1, 2], size=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Display some of the generated labels\n",
        "print(f'The first 10 class labels are: {y[:10]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# OneHotEncoder to convert labels into One-Hot format\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_onehot = encoder.fit_transform(y.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Build a simple neural network model\n",
        "model = Sequential([\n",
        "    Dense(10, input_dim=3, activation='relu'),  # Hidden layer with 10 neurons\n",
        "    Dense(3, activation='softmax')  # Output layer with 3 neurons for 3 classes\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',  # Loss function for multi-class classification\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test loss: {test_loss}')\n",
        "print(f'Test accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Plot the loss and accuracy during training\n",
        "plt.figure(figsize=(12, 6))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Training and validation loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss during Training')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy during Training')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Make predictions on new data\n",
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Convert prediction probabilities to classes\n",
        "predicted_classes = np.argmax(predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Convert test labels to classes\n",
        "y_test_classes = np.argmax(y_test, axis=1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
